{"id":"paper_2025080900001","title":"LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning","authors":"Jiahao Zhao","journal":"ArXiv","year":"2024","doi":"2508.03275v1","url":"https://arxiv.org/html/2508.03275v1","keyAssumptions":"Items can be scheduled independently without semantic relationships; Temporal spacing alone is sufficient for optimal learning; Traditional algorithms work across all domains","citation":"Zhao, J. (2024). LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning. arXiv preprint arXiv:2508.03275.","notes":"First algorithm addressing semantic interference through LLM-powered similarity assessment. Achieves 90.2% vs 88.4% success rate. Addresses critical semantic confusion in vocabulary learning.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025080900002","title":"Human-like Forgetting Curves in Deep Neural Networks","authors":"Dylan Kline","journal":"ArXiv","year":"2025","doi":"2506.12034v2","url":"https://arxiv.org/abs/2506.12034","keyAssumptions":"Neural network forgetting is fundamentally different from human forgetting; Catastrophic forgetting requires specialized architectures; Human memory research has limited AI applicability","citation":"Kline, D. (2025). Human-like Forgetting Curves in Deep Neural Networks. arXiv preprint arXiv:2506.12034.","notes":"Demonstrates neural networks exhibit human-like exponential forgetting patterns. Enables direct application of spaced repetition to mitigate catastrophic forgetting. Bridges cognitive science and AI.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025080900003","title":"Optimizing Human Learning","authors":"Behzad Tabibian, Utkarsh Upadhyay, Abir De, Ali Zarezade, Bernhard Schölkopf, Manuel Gomez-Rodriguez","journal":"ArXiv","year":"2017","doi":"1712.01856","url":"https://ar5iv.labs.arxiv.org/html/1712.01856","keyAssumptions":"Heuristic scheduling rules are sufficient; Optimal scheduling cannot be derived mathematically; Memory models too complex for optimization","citation":"Tabibian, B., Upadhyay, U., De, A., Zarezade, A., Schölkopf, B., & Gomez-Rodriguez, M. (2017). Optimizing human learning. arXiv preprint arXiv:1712.01856.","notes":"First theoretical proof that optimal spaced repetition schedules are determined by recall probability. Uses marked temporal point processes framework. Validated on Duolingo data.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025080900004","title":"Algorithm SM-18","authors":"Piotr Wozniak","journal":"SuperMemo.guru","year":"2019","doi":"","url":"https://supermemo.guru/wiki/Algorithm_SM-18","keyAssumptions":"Item difficulty is constant throughout learning; Single memory strength parameter sufficient; Fixed mathematical formulas for intervals","citation":"Wozniak, P. (2019). Algorithm SM-18. SuperMemo.guru. Retrieved from https://supermemo.guru/wiki/Algorithm_SM-18","notes":"Latest SuperMemo algorithm with dynamic difficulty estimation. Replaces assumption of constant item difficulty with adaptive modeling. Part of 34-year algorithm evolution achieving 1.1 to 35.3 improvement ratio over SM-2.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025080900005","title":"Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students","authors":"Prital Bamnodkar","journal":"ArXiv","year":"2025","doi":"2507.21109","url":"https://arxiv.org/html/2507.21109","keyAssumptions":"Experience replay alone sufficient for continual learning; Random memory sampling is optimal; Human learning strategies don't apply to neural networks","citation":"Bamnodkar, P. (2025). Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students. arXiv preprint arXiv:2507.21109.","notes":"Applies Active Recall, Deliberate Practice, and Spaced Repetition to continual learning. Achieves 13.17% vs 7.40% on Split CIFAR-100. Demonstrates human learning principles enhance neural network training.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025080900006","title":"Evolvable Psychology Informed Neural Network for Memory Behavior Modeling","authors":"Xiaoxuan Shen, Zhihai Hu, Qirong Chen, Shengyingjie Liu, Ruxia Liang, Jianwen Sun","journal":"ArXiv","year":"2023","doi":"2408.14492v1","url":"https://arxiv.org/html/2408.14492v1","keyAssumptions":"Memory equations have fixed descriptors; Pure mathematical or data-driven approaches are optimal; Classical memory theories cannot be improved through ML","citation":"Shen, X., Hu, Z., Chen, Q., Liu, S., Liang, R., & Sun, J. (2023). Evolvable Psychology Informed Neural Network for Memory Behavior Modeling. arXiv preprint arXiv:2408.14492.","notes":"Combines neural networks with differentiating sparse regression to evolve memory equation descriptors. Addresses controversies in memory equation formulation. Shows AI can enhance traditional psychological models.","addedDate":"2025-08-09T20:57:00Z"}
{"id":"paper_2025081100007","title":"Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review","authors":"Neha Prakriya, Jui-Nan Yen, Cho-Jui Hsieh, Jason Cong","journal":"ArXiv","year":"2025","doi":"2409.06131v2","url":"https://arxiv.org/html/2409.06131v2","keyAssumptions":"Random data sampling optimal for LLM training; All data points equally valuable; Forgetting purely detrimental; Human learning techniques don't apply to large-scale training","citation":"Prakriya, N., Yen, J-N., Hsieh, C-J., & Cong, J. (2025). Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review. arXiv preprint arXiv:2409.06131.","notes":"Learn-Focus-Review paradigm achieves lower perplexity using only 5%-19% of training tokens. Matches 2× parameter models with 3.2% tokens. First massive-scale validation of spaced repetition in LLM training.","addedDate":"2025-08-11T18:36:00Z"}
{"id":"paper_2025081100008","title":"Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing","authors":"Grey Kuling, Marinka Zitnik","journal":"ArXiv","year":"2025","doi":"2507.00032","url":"https://arxiv.org/abs/2507.00032","keyAssumptions":"Knowledge tracing requires extensive cohort data; Gradient-based learning with backprop necessary; Memory should preserve all information; Biological principles don't scale","citation":"Kuling, G., & Zitnik, M. (2025). Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing. arXiv preprint arXiv:2507.00032.","notes":"Biologically inspired architecture with time-decaying Hebbian memory. Enables few-shot personalization. 1.75× faster training, 99.01% less memory usage. Validated in classroom deployment.","addedDate":"2025-08-11T18:36:00Z"}
{"id":"paper_2025081100009","title":"Adaptive Forgetting Curves for Spaced Repetition Language Learning","authors":"Francisco J. Valverde-Albacete, Carmen Peláez-Moreno","journal":"PMC","year":"2020","doi":"PMC7334729","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC7334729/","keyAssumptions":"Universal forgetting curves apply to all learners; Simple temporal spacing sufficient; Word difficulty uniform; Neural networks cannot capture psychological patterns","citation":"Valverde-Albacete, F. J., & Peláez-Moreno, C. (2020). Adaptive Forgetting Curves for Spaced Repetition Language Learning. PMC. doi: PMC7334729","notes":"Word complexity highly informative feature learned by neural networks. 4.28M learner-word datapoints from Duolingo. Demonstrates neural networks can effectively model psychological forgetting patterns.","addedDate":"2025-08-11T18:36:00Z"}
{"id":"paper_2025081100010","title":"DRL-SRS: A Deep Reinforcement Learning Approach for Optimizing Spaced Repetition Schedules","authors":"Jing Wang, Qinfeng Xiao","journal":"Applied Sciences","year":"2024","doi":"10.3390/app14135591","url":"https://www.mdpi.com/2076-3417/14/13/5591","keyAssumptions":"Handcrafted spacing rules sufficient; DRL should focus on item selection; One item per day constraint; Simple temporal intervals adequate","citation":"Wang, J., et al. (2024). DRL-SRS: A Deep Reinforcement Learning Approach for Optimizing Spaced Repetition Schedules. Applied Sciences, 14(13), 5591.","notes":"Focus on optimal intervals vs. item selection. 64% error reduction, 17% cost reduction. 220M row dataset with time-series information. Transformer-based half-life regression.","addedDate":"2025-08-11T18:36:00Z"}
{"id":"paper_2025081100011","title":"Forgetting in Machine Learning and Beyond: A Survey","authors":"Alyssa Shuang Sha, Bernardo Pereira Nunes, Armin Haller","journal":"ArXiv","year":"2024","doi":"2405.20620","url":"https://arxiv.org/abs/2405.20620","keyAssumptions":"Forgetting purely detrimental in ML; Memory should preserve all information; Human forgetting mechanisms don't apply to AI; Catastrophic forgetting unsolvable flaw","citation":"Sha, A. S., Nunes, B. P., & Haller, A. (2024). Forgetting in Machine Learning and Beyond: A Survey. arXiv preprint arXiv:2405.20620.","notes":"Comprehensive survey showing forgetting as adaptive function. Benefits across ML subfields: performance improvement, overfitting prevention, data privacy. Paradigm shift from problem to solution.","addedDate":"2025-08-11T18:36:00Z"}
{"id":"paper_2025081100012","title":"FSRS Algorithm: Free Spaced Repetition Scheduler","authors":"Jarrett Ye, Open Spaced Repetition Community","journal":"GitHub/ArXiv","year":"2025","doi":"","url":"https://github.com/open-spaced-repetition/fsrs4anki","keyAssumptions":"Hand-crafted SM-2 algorithm optimal; Fixed mathematical formulas sufficient; One-size-fits-all approach works; Psychological theory better than data-driven methods","citation":"Ye, J. et al. (2025). FSRS Algorithm: Free Spaced Repetition Scheduler. GitHub. Retrieved from https://github.com/open-spaced-repetition/fsrs4anki","notes":"Machine learning-optimized algorithm achieving 30% efficiency gain over SM-2. Uses 19-21 parameters trained on hundreds of millions of reviews. First successful replacement of SM-2 after 37 years.","addedDate":"2025-08-11T18:46:00Z"}
{"id":"paper_2025081100013","title":"Do Your Best and Get Enough Rest for Continual Learning","authors":"Hankyul Kang, Gregor Seifer, Donghyun Lee, Jongbin Ryu","journal":"CVPR","year":"2025","doi":"2503.18371","url":"https://arxiv.org/abs/2503.18371","keyAssumptions":"Continuous training optimal; More frequent learning always better; Human memory principles don't apply to neural networks; Rest periods are wasted time","citation":"Kang, H., Seifer, G., Lee, D., & Ryu, J. (2025). Do Your Best and Get Enough Rest for Continual Learning. CVPR 2025.","notes":"View-batch model applies Ebbinghaus forgetting curve theory to neural networks. Strategic rest periods improve continual learning. Validates 140-year-old psychological principles in modern AI.","addedDate":"2025-08-11T18:46:00Z"}
{"id":"paper_2025081100014","title":"Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory","authors":"Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, James Zou","journal":"ArXiv","year":"2025","doi":"2504.07952","url":"https://arxiv.org/abs/2504.07952","keyAssumptions":"Stateless query processing optimal; Each problem solved from scratch; Fine-tuning only way to improve; Test-time learning requires labels","citation":"Suzgun, M., Yuksekgonul, M., Bianchi, F., Jurafsky, D., & Zou, J. (2025). Dynamic Cheatsheet: Test-Time Learning with Adaptive Memory. arXiv preprint arXiv:2504.07952.","notes":"Persistent memory framework enabling >2× accuracy gains without parameter changes. Claude 3.5 Sonnet doubled AIME performance. GPT-4o: 10%→99% on Game of 24.","addedDate":"2025-08-11T18:46:00Z"}
{"id":"paper_2025081100015","title":"Revisiting Replay and Gradient Alignment for Continual Pre-Training of Large Language Models","authors":"Istabrak Abbes, Gopeshh Subbaraj, Matthew Riemer, Nizar Islah, Benjamin Therien, Tsuguchika Tabaru, Hiroaki Kingetsu, Sarath Chandar, Irina Rish","journal":"ArXiv","year":"2025","doi":"2508.01908","url":"https://arxiv.org/abs/2508.01908","keyAssumptions":"Complete retraining necessary for new data; Replay doesn't scale to 100B+ tokens; Gradient alignment too expensive for LLMs; Model scaling better than replay","citation":"Abbes, I. et al. (2025). Revisiting Replay and Gradient Alignment for Continual Pre-Training of Large Language Models. arXiv preprint arXiv:2508.01908.","notes":"Experience replay enables stable continual learning in 100B+ token LLM training. Small replay rates more valuable than model scaling. First gradient alignment demo at LLM scale.","addedDate":"2025-08-11T18:46:00Z"}